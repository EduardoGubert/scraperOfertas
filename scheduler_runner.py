"""
Scheduler Runner - Executa scraper em intervalos regulares
Mant√©m o programa rodando continuamente (SEM DEPEND√äNCIAS EXTERNAS)
"""

import asyncio
import time
import logging
import sys
import os
import threading
from datetime import datetime, timedelta
from pathlib import Path

# Adiciona o diret√≥rio atual ao path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from scraper_ml_afiliado import ScraperMLAfiliado

class ScraperScheduler:
    def __init__(self, intervalo_minutos=30, max_produtos=50):
        self.intervalo_minutos = intervalo_minutos
        self.max_produtos = max_produtos
        self.rodando = False
        self.proximo_run = None
        self.setup_logging()
        
    def setup_logging(self):
        """Configura logging para o scheduler"""
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)
        
        log_file = log_dir / f"scheduler_{datetime.now().strftime('%Y%m%d')}.log"
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        
        self.logger = logging.getLogger(__name__)

    async def executar_scraping(self):
        """Executa uma sess√£o de scraping"""
        try:
            self.logger.info(f"üöÄ Iniciando scraping agendado - {self.max_produtos} produtos")
            
            async with ScraperMLAfiliado(
                headless=True,  # Execu√ß√£o em background
                max_produtos=self.max_produtos,
                usar_cache=True
            ) as scraper:
                
                # Verifica se precisa fazer login
                if not await scraper.verificar_login():
                    self.logger.warning("‚ö†Ô∏è Login necess√°rio - scraping cancelado")
                    return
                
                # Executa scraping
                produtos = await scraper.scrape_ofertas()
                
                # Salva resultados
                if produtos:
                    arquivo = await scraper.salvar_resultados(produtos)
                    
                    sucesso = sum(1 for p in produtos if p["status"] == "sucesso")
                    total = len(produtos)
                    
                    self.logger.info(f"‚úÖ Scraping conclu√≠do: {sucesso}/{total} produtos com link")
                    self.logger.info(f"üíæ Resultados salvos: {arquivo}")
                    
                    # Estat√≠sticas do cache
                    if scraper.usar_cache:
                        stats = scraper.estatisticas_cache()
                        self.logger.info(f"üìä Cache total: {stats['total_produtos']} produtos")
                else:
                    self.logger.info("üéØ Nenhum produto novo encontrado")
                    
        except Exception as e:
            self.logger.error(f"‚ùå Erro no scraping agendado: {e}")
            import traceback
            self.logger.error(f"üìã Stack trace: {traceback.format_exc()}")

    def job_wrapper(self):
        """Wrapper para executar job ass√≠ncrono"""
        try:
            asyncio.run(self.executar_scraping())
        except Exception as e:
            self.logger.error(f"‚ùå Erro cr√≠tico no scheduler: {e}")

    def calcular_proximo_run(self):
        """Calcula hor√°rio da pr√≥xima execu√ß√£o"""
        self.proximo_run = datetime.now() + timedelta(minutes=self.intervalo_minutos)
        return self.proximo_run

    def iniciar_scheduler(self):
        """Inicia o scheduler cont√≠nuo"""
        self.logger.info("="*60)
        self.logger.info("üïê SCHEDULER SCRAPER ML - egnOfertas")
        self.logger.info("="*60)
        self.logger.info(f"‚è∞ Intervalo: {self.intervalo_minutos} minutos")
        self.logger.info(f"üì¶ Max produtos: {self.max_produtos}")
        
        self.rodando = True
        
        # Execu√ß√£o inicial
        self.logger.info("üîÑ Executando primeira sess√£o...")
        self.job_wrapper()
        
        # Calcula pr√≥xima execu√ß√£o
        self.calcular_proximo_run()
        self.logger.info(f"üöÄ Pr√≥xima execu√ß√£o: {self.proximo_run.strftime('%d/%m/%Y %H:%M:%S')}")
        
        # Loop principal
        try:
            while self.rodando:
                agora = datetime.now()
                
                # Verifica se √© hora de executar
                if agora >= self.proximo_run:
                    self.logger.info(f"‚è∞ Hora de executar - {agora.strftime('%H:%M:%S')}")
                    self.job_wrapper()
                    
                    # Calcula pr√≥xima execu√ß√£o
                    self.calcular_proximo_run()
                    self.logger.info(f"üöÄ Pr√≥xima execu√ß√£o: {self.proximo_run.strftime('%d/%m/%Y %H:%M:%S')}")
                
                # Aguarda 1 minuto antes de verificar novamente
                time.sleep(60)
                
                # Log de status a cada hora
                if agora.minute == 0:
                    tempo_restante = self.proximo_run - agora
                    minutos_restantes = int(tempo_restante.total_seconds() / 60)
                    self.logger.info(f"üíì Scheduler ativo - {minutos_restantes} min para pr√≥xima execu√ß√£o")
                    
        except KeyboardInterrupt:
            self.logger.info("üõë Scheduler interrompido pelo usu√°rio")
            self.rodando = False
        except Exception as e:
            self.logger.error(f"‚ùå Erro cr√≠tico no scheduler: {e}")
            self.rodando = False

    def parar_scheduler(self):
        """Para o scheduler"""
        self.rodando = False
        self.logger.info("üõë Parando scheduler...")

def main():
    """Fun√ß√£o principal"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Scheduler para Scraper ML')
    parser.add_argument('--intervalo', type=int, default=30, 
                       help='Intervalo em minutos (padr√£o: 30)')
    parser.add_argument('--produtos', type=int, default=50,
                       help='N√∫mero m√°ximo de produtos (padr√£o: 50)')
    parser.add_argument('--agora', action='store_true',
                       help='Executa uma vez agora e sai')
    
    args = parser.parse_args()
    
    scheduler = ScraperScheduler(
        intervalo_minutos=args.intervalo,
        max_produtos=args.produtos
    )
    
    if args.agora:
        # Execu√ß√£o √∫nica
        scheduler.logger.info("üîÑ Execu√ß√£o √∫nica solicitada")
        scheduler.job_wrapper()
    else:
        # Scheduler cont√≠nuo
        scheduler.iniciar_scheduler()

if __name__ == "__main__":
    main()